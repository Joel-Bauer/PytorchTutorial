{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joel-Bauer/PytorchTutorial/blob/main/COLAB_MNIST_with_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLIezsVXkb8J"
      },
      "source": [
        "# Welcome to PyTorch!\n",
        "The purpose of this little tutorial is to introduce you to the basics of the PyTorch deep learning package, and how to structure a small project.\n",
        "We will use a classic deep learning introductory problem, classification of single hand writen digets from the MNIST databse (Modified National Institute of Standards and Technology database).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation and Setup\n",
        "\n",
        "Before we begin, please make sure to go to `File > Save a Copy in Drive`. This makes sure that any changes you make are saved just for you, and not the whole group! Once you've copied the file, go to `Runtime > Change Runtime Type`, and select __GPU__ under Hardware Accelerator."
      ],
      "metadata": {
        "id": "4dRnpXpXklNp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "%cd gdrive/MyDrive/\n",
        "\n",
        "if not os.path.isdir(os.path.join(os.getcwd(), \"PytorchTutorial\")):\n",
        "  ! git clone https://github.com/Joel-Bauer/PytorchTutorial.git\n",
        "  %cd PytorchTutorial\n",
        "  ! pip install -r requirements.txt\n",
        "else:\n",
        "  ! git pull origin main\n",
        "  ! pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "AdN2-S7UkoHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GeAW6dL-d7Sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "Just run the cell below"
      ],
      "metadata": {
        "id": "1UE10cvCxH1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython import display\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "p7lYdXLUxVEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper and Plotting Functions\n",
        "Just run the cell below"
      ],
      "metadata": {
        "id": "3vkXCTs6xNXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_examples(imgs, labels, Label_predictions):\n",
        "    figure = plt.figure(figsize=(8, 8))\n",
        "    cols, rows = 5, 5\n",
        "    for i in range(1, cols * rows + 1):\n",
        "        figure.add_subplot(rows, cols, i) \n",
        "        if len(Label_predictions)<1:\n",
        "            plt.title(np.array2string(labels[i]) )\n",
        "        else:\n",
        "            plt.title(np.array2string(labels[i]) + '(' + np.array2string(Label_predictions[i]) + ')')\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(imgs[i].squeeze(), cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zqxCc0u8xvFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azqLHmODkb8L"
      },
      "source": [
        "# 0) Import torch and check if our workstation has a CUDA enabled GPU "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqrSf6hPkb8L"
      },
      "outputs": [],
      "source": [
        "import torch as torch # import the pytorch library\n",
        "\n",
        "# if a cuda enabled GPU device is available get a handle(?) to it, otherwise create a handle to the cpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "device "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWMXq0E_kb8M"
      },
      "source": [
        "# 1) Getting and Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1) Download MNIST data from the torchvision library. \n",
        "Torchvision needs to be imported separatly. "
      ],
      "metadata": {
        "id": "bAwmgnsz1-sx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCy-srNAkb8N"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# pytorch has several datasets you can download, including the MNIST hand-written digit\n",
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,                         \n",
        "    transform = ToTensor(), \n",
        "    download = True          \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dll9Mlzkb8O"
      },
      "source": [
        "Above we have downloaded the training set. Fill out the code below to to download the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOUILD-qkb8O"
      },
      "outputs": [],
      "source": [
        "test_data = datasets.MNIST(\n",
        "    root = 'data', #! cut\n",
        "    train = False, #! cut\n",
        "    transform = ToTensor(), #! cut\n",
        "    download = True #! cut\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6E9Tp75kb8O"
      },
      "source": [
        "## 1.2) Let's have a look at the dataset we've just downloaded\n",
        "\n",
        "The MNIST data is composed of images and corresponding labels.\n",
        "To plot an example of the data, we will use matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHyIu5q4kb8P"
      },
      "outputs": [],
      "source": [
        "print(train_data) \n",
        "print(test_data)\n",
        "\n",
        "# call an example of an image and its label. What are the dimensions of the image and what is the label for this example?\n",
        "img, label = train_data[0] #! cut\n",
        "print(img.shape) #! cut\n",
        "print(label) #! cut\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_1MeT30kb8Q"
      },
      "outputs": [],
      "source": [
        "# plot the example image \n",
        "figure = plt.figure(figsize=(3, 3))\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\") #! cut\n",
        "plt.title(label)\n",
        "plt.axis(\"off\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv3ZB2bmkb8S"
      },
      "source": [
        "## 1.3) Loading your own data\n",
        "\n",
        "Above we downloaded an existing dataset from torchvision. In many cases you will want to import your own data from .mat, .npy and .npz files. Below is an example of how that might work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gysmw8ZUkb8S"
      },
      "outputs": [],
      "source": [
        "## save MNIST data as numpy arrays\n",
        "\n",
        "# imgs = train_data.data.detach().numpy()\n",
        "# labels = train_data.targets.detach().numpy()\n",
        "# np.savez('MNIST_train.npz',imgs=imgs,labels=labels)\n",
        "\n",
        "# imgs = test_data.data.detach().numpy()\n",
        "# labels = test_data.targets.detach().numpy()\n",
        "# np.savez('MNIST_test.npz',imgs=imgs,labels=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwDhLnrYkb8T"
      },
      "outputs": [],
      "source": [
        "# # Loading from disk\n",
        "# data = np.load('MNIST_train.npz') # load data from .npz file\n",
        "# labels=data['labels']\n",
        "# imgs=data['imgs'] \n",
        "# imgs=torch.from_numpy(imgs) # convert numpy array to torch tensor\n",
        "# imgs=imgs.to(torch.float32) # specify dtype as float32 (dtype must match the model dtype whos default is usually float32)\n",
        "# train_data = torch.utils.data.TensorDataset(imgs,torch.from_numpy(labels))\n",
        "\n",
        "# # same thing for the test set\n",
        "# data = np.load('MNIST_test.npz')\n",
        "# imgs=torch.from_numpy(data['imgs']).to(torch.float32)\n",
        "# labels=data['labels']\n",
        "# test_data = torch.utils.data.TensorDataset(imgs,torch.from_numpy(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsP9gsQDkb8T"
      },
      "source": [
        "## 1.4) Create a data loader\n",
        "\n",
        "DataLoaders, the function, wraps an iterable around a DataSet class. This provides an easy way of sampling from the dataset in an efficient way. This is also where we can specifiy the batch size, as well as introduce data transforms that can be applied each time we sample from the data.\n",
        "\n",
        "- batch size: The size of your data sample used for each optimization step. This is a hyperparameter, i.e. a variable you can optimize to improve good model performance quickly.\n",
        "\n",
        "- transforms: We might need to rescale our images. Or we would like to augment our training data, e.g. by flipping the images horizontally or introducing noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w2K-xYikb8T"
      },
      "outputs": [],
      "source": [
        "# setup DataLoader",
        "batchsize = 64 # This is usually a multiple of 2 between 16 and 512 and will depend on your CPU/GPU size\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "loaders = { # Library of data loader functions\n",
        "    'train' : torch.utils.data.DataLoader(train_data, \n",
        "                                          batch_size=batchsize, \n",
        "                                          shuffle=True, # We usually want to randomly sample a new subset of our data\n",
        "                                          num_workers=1), # This variable allows us to multithread dataloading, \n",
        "                                                          # which is usefull if we have a dataset which does not fit onto the RAM\n",
        "    \n",
        "    'test'  : torch.utils.data.DataLoader(test_data, \n",
        "                                          batch_size=batchsize, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSCZYTWokb8U"
      },
      "source": [
        "Let's call the data loader to call one batch and plot the examples in that batch. We have writen a plotting function that plots a few exampels with labels in one figure for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dVTLO1xkb8U"
      },
      "outputs": [],
      "source": [
        "training_data_iterable = iter(loaders['train']) # create an iterable \n",
        "img, label=next(training_data_iterable) # calls the first randomly sampled batch of examples\n",
        "plot_examples(img, label, []) # plots a few examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7xeIVolkb8V"
      },
      "source": [
        "# 2) Create or call a model\n",
        "This is the fun bit! We have written up a couple of models in this tutorial for you and for now we will just use one of these, but feel free to go back and modify one of them or make another one from scratch. \n",
        "\n",
        "In this digit classification exercise, the major constraints of your model are the size of the input layer, which needs to match your input data (channels \\* height \\* width => 1 \\* 28 \\* 28), and the size of your output layer, which needs to match the number of possible classes/lables (0-9 => 10). \n",
        "\n",
        "#### Feed Forward Models\n",
        "\n",
        "- LFF: No hidden layers. This is a linear model because it cannot learn nonlinear relationships.\n",
        "\n",
        "- DFF_tiny: This model has 10 hidden units\n",
        "\n",
        "- DFF: Still a fairly shallow model (not many hidden layers), but with more hidden units\n",
        "\n",
        "#### Convolutional Models (not implemented yet)\n",
        "\n",
        "- ConvNet1: The first two layers are convolutional layers, which is then followed by one fully connected feed forward layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U2bAF_kkb8V"
      },
      "source": [
        "We will use the DFF model for our example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLHuzVWtkb8V"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary \n",
        "from Models import DFF as model    # try other models too!\n",
        "\n",
        "net = model().to(device) # Call an instance of the model\n",
        "\n",
        "summary(net, (1, 28, 28)) # this gives us a convenient way of quickly looking at the structure and size of our model. \n",
        "\n",
        "# We will want to cellect the model performance as we train it. So let's initiate this list here\n",
        "loss_train = [] # loss collector\n",
        "loss_test = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQcHSqs5kb8W"
      },
      "source": [
        "### 2.1) Visualization\n",
        "It is often usefull to visualize our models in the form of flow charts, especially when they get large and complicated. There are several tools you can use. Try using the [Netron online app](https://netron.app). You will need to generate a .onnx file to do this by running the cell below. Then right click on the generated file in the sidebar to download. Drag-and-drop the .onnx file into the web app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSGysA_Xkb8W"
      },
      "outputs": [],
      "source": [
        "import torch.onnx\n",
        "\n",
        "img, label = next(iter(loaders['train'])) # get a batch\n",
        "torch.onnx.export(net, img.to(device), 'MNIST_DFF.onnx', export_params=True, input_names=['image'], output_names=['label'],\n",
        "                  dynamic_axes={'image' : {0 : 'batch_size'},'label' : {0 : 'batch_size'}}) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s-DjWnwkb8W"
      },
      "source": [
        "# 3) Helper functions for training\n",
        "We will want to create a couple helper functions to train and evaluate our model. \n",
        "\n",
        "- loss function: This calculates the difference between the predicted labels and the true labels across your batch. There are many loss functions, but usually there is a standard loss function for the problem you are working on. For Classification, Cross Entropy is commonly used. This loss is then used to caculate the gradient across the model, which in turn is used to update the weights and biases in the model in a process called gradient decent.\n",
        "\n",
        "- gradient calculator: just kidding! Pytorch takes care of this for you. \n",
        "\n",
        "- optimizer: After we calculate the loss, we need to apply gradient decent. The aim is to decrease the loss. However, there are a number of ways this can be applied. We therefore need to choose an optimizer function.\n",
        "\n",
        "- accuracy: We usually also want to know the proportion of correctly identified examples, even though that is not used for gradient descent.\n",
        "\n",
        "- Wrapper: It is helpfull to write a function, which applies the above steps in the correct order and only when appropriate (e.g. you should disable optimization when applying your model to test data).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcJAz8IXkb8X"
      },
      "outputs": [],
      "source": [
        "## Loss function\n",
        "from torch import nn\n",
        "\n",
        "Loss_func = nn.CrossEntropyLoss()\n",
        "# Loss_func = nn.MSELoss() # Alternative: would need to convert label to one-hot-vector -> nn.functional.one_hot(label,num_classes=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQk81Jx8kb8X"
      },
      "outputs": [],
      "source": [
        "## accuracy\n",
        "def accuracy_calc(labels,labels_pred_int): \n",
        "    # labels: true labels (in integer from, not a one-hot-vector)\n",
        "    # labels_pred_int: predicted labels (in integer from, not a vector of probabilities)\n",
        "    labels = labels.cpu().detach().numpy() # to use numpy we need to move the tensor of labels off the GPU and convert it to a numpy array\n",
        "    labels_pred_int = labels_pred_int.cpu().detach().numpy()\n",
        "    return 100*(labels_pred_int == labels).sum().item() / np.shape(labels)[0] # Here, we calculate the percent correctly predicted labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Obxrhmekb8X"
      },
      "source": [
        "There are a number of different optimization algorithms and components thereof. \n",
        "\n",
        "- Batch gradient descent: calculate the gradient across the entire training data set and then perform one optimization step.\n",
        "\n",
        "- Stocastic gradient decent (SGD): calculate the gradient and apply an optimization step for each training sample independently.\n",
        "\n",
        "- Mini-batch gradient descent: for each batch (e.g. 32 training examples) calculate the gradient and apply one step of optimization. Usually preferable to the batch gradient decent or true SGD.\n",
        "\n",
        "- Momentum: uses a rolling average of the gradient, so that noise across batches is minimized. This smooths the learning \"trajectory\".\n",
        "\n",
        "- Adaptive learning rate: when we are far away from the global optimum a larger learning rate is advantageous as it speeds up progress, but as we approach the global minimum small steps are better. \n",
        "\n",
        "Note: confusingly the PyTorch function `torch.optim.SGD` does not perform Stocastic gradient decent strictly speaking. It will optimize based on the accumulated gradient, of which the step size is defined by us. You will see what this means below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TU4Jrihkb8Y"
      },
      "outputs": [],
      "source": [
        "## optimizer\n",
        "from torch import optim\n",
        "\n",
        "# We will use \n",
        "lr = 0.01 \n",
        "momentum = 0.5 # try 0\n",
        "optimizer = optim.SGD(net.parameters(),momentum=momentum,lr=lr) # stocastic gradient decent\n",
        "# optimizer = optim.Adam(net.parameters()) # more advanced alternative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-hZwerGkb8Y"
      },
      "source": [
        "Let's wrap things up!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udTzvDR3kb8Y"
      },
      "outputs": [],
      "source": [
        "## Wrapper function\n",
        "def run_model(img,labels,model,optimizer,Loss_func,train=False):\n",
        "    if train: # only important in specific instances (e.g. if your model has dropout layers or variational layers)\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    \n",
        "    optimizer.zero_grad() # otherwise gradients will accumulate. \n",
        "\n",
        "    labels_pred = model(img)  # run model and get label predictions\n",
        "    labels_pred_int = labels_pred.argmax(axis=1) # our model spits out a probability for each category (label) to be true. This line gets the index of max probability for each example.\n",
        "    loss = Loss_func(labels_pred,labels) # calculate the loss (only uses one channel)\n",
        "    accuracy = accuracy_calc(labels,labels_pred_int) # calculate the % correct predictions\n",
        "\n",
        "    # we only want this next bit to be true when specified, i.e. when we are training the model\n",
        "    if train:\n",
        "        # backprob and update\n",
        "        loss.backward() # calculates the gradient based on the current loss\n",
        "        optimizer.step() # applies one optimization step\n",
        "    \n",
        "    return loss, labels_pred, labels_pred_int, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnVAUysDkb8Y"
      },
      "source": [
        "It's a good idea to check things are working before training your model. Get a training example batch, run it through the model using the wrapper function above and print the outs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c84uDW5Gkb8Z"
      },
      "outputs": [],
      "source": [
        "# check its all working\n",
        "img, label=next(iter(loaders['train'])) #! cut # get a batch\n",
        "img = img.to(device) #! cut\n",
        "label = label.to(device) #! cut \n",
        "batch_loss, label_pred, label_pred_int, accuracy = run_model(img, label, net, optimizer, Loss_func) #! cut\n",
        "\n",
        "label=label.cpu().detach().numpy()\n",
        "batch_loss=batch_loss.cpu().detach().numpy()\n",
        "label_pred=label_pred.cpu().detach().numpy()\n",
        "label_pred_int=label_pred_int.cpu().detach().numpy()\n",
        "\n",
        "print('label:            ' + np.array2string(label))\n",
        "print('label prediction: ' + np.array2string(label_pred_int))\n",
        "print('label weights first example: ' + np.array2string(label_pred[0]*100,precision=0,suppress_small=True))\n",
        "print('loss: ' + np.array2string(batch_loss))\n",
        "print('accuracy: ' + str(accuracy) + '%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW0BuCrDkb8Z"
      },
      "source": [
        "# 4) Training time\n",
        "\n",
        "It's finally time to train our model. We will do this using two `for` loops. The nested loop will sample batches of data and optimize the model on each iteration until all examples in the training set have been used once. The second loop will repeat these passes over the training set a given number of times (epochs), as well as calculate and plot the loss for the training and test set at the end of each epoch.\n",
        "\n",
        "But first lets caculate the training and test loss before any optimization has occured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QOqvb9Pkb8Z"
      },
      "outputs": [],
      "source": [
        "if len(loss_train)<1: # if no training has happened yet save initial loss value\n",
        "    img, label=next(iter(loaders['train'])) # get one batch\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "    batch_loss, _, _, _ = run_model(img, label, net, optimizer, Loss_func)\n",
        "    loss_train.append(batch_loss.cpu().detach().numpy())\n",
        "\n",
        "if len(loss_test)<1: # if no training has happened yet save initial loss value\n",
        "    img, label=next(iter(loaders['test'])) # get one batch\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "    batch_loss, _, _, _ = run_model(img, label, net, optimizer, Loss_func)\n",
        "    loss_test.append(batch_loss.cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnjGM8K8kb8a"
      },
      "source": [
        "We will use the `tqdm` package (giving us a progress bar) to keep track of the progress through the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jnEHHIgkb8a"
      },
      "outputs": [],
      "source": [
        "# training loop\n",
        "epochs = 30 # \n",
        "\n",
        "plt.figure()\n",
        "for ep_n in range(epochs):\n",
        "\n",
        "    for img,label in tqdm(loaders['train']):\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)\n",
        "        net.train()\n",
        "        run_model(img, label, net, optimizer, loss, train=True)\n",
        "\n",
        "    # train set loss\n",
        "    img, label=next(iter(loaders['train'])) # get a batch\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "    batch_loss, _, _, _ = run_model(img,label,net,optimizer,Loss_func)\n",
        "    loss_train.append(batch_loss.cpu().detach().numpy())\n",
        "\n",
        "    # test set loss\n",
        "    img, label=next(iter(loaders['test'])) # get a batch\n",
        "    img = img.to(device)\n",
        "    label = label.to(device)\n",
        "    batch_loss, _, _, _ = run_model(img, label, net, optimizer, Loss_func)\n",
        "    loss_test.append(batch_loss.cpu().detach().numpy())\n",
        "\n",
        "    # plot the losses\n",
        "    plt.clf()\n",
        "    train_handle = plt.plot(loss_train, color='blue',label='training set')\n",
        "    test_handle = plt.plot(loss_test, color='red',label='test set')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend()\n",
        "    display.clear_output(wait=True) # necessary in order to refresh the plot, otherwise it will print a new plot each epoch\n",
        "    display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMNE8K8xkb8a"
      },
      "source": [
        "# 5) Evaluating Performance\n",
        "\n",
        "If all has gone well our loss function should have decreased substantially and reached a plateau. Or you've gotten bored, cut the training of early and just see how well the model is doing right now.\n",
        "\n",
        "To get a feeling of for the models performance', we will get multiple batches of test data, caculate the classificiation accuracy of the this set and then plot a few examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg_Ngsq9kb8b"
      },
      "outputs": [],
      "source": [
        "# check its all working\n",
        "loader_temp = iter(loaders['test'])\n",
        "img, label = next(loader_temp) # get a batch\n",
        "\n",
        "for i in range(10): # get multiple batches to get more accurate estimates\n",
        "    img_temp, label_temp = next(loader_temp)\n",
        "    img = torch.cat((img, img_temp), dim=0)\n",
        "    label = torch.cat((label, label_temp), dim=0)\n",
        "\n",
        "img = img.to(device)\n",
        "label = label.to(device)\n",
        "batch_loss, label_pred, label_pred_int, accuracy = run_model(img, label, net, optimizer, Loss_func)\n",
        "\n",
        "\n",
        "img = img.cpu().detach().numpy()\n",
        "label = label.cpu().detach().numpy()\n",
        "batch_loss = batch_loss.cpu().detach().numpy()\n",
        "label_pred = label_pred.cpu().detach().numpy()\n",
        "label_pred_int = label_pred_int.cpu().detach().numpy()\n",
        "\n",
        "print('label: ' + np.array2string(label[0:31]))\n",
        "print('label prediction: ' + np.array2string(label_pred_int[0:31]))\n",
        "print('label weights first example: ' + np.array2string(label_pred[0]*100, precision=0, suppress_small=True))\n",
        "print('loss: ' + np.array2string(batch_loss))\n",
        "print('accuracy: ' + str(round(accuracy, 2)) + '%')\n",
        "\n",
        "plot_examples.plot(img, label, label_pred_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6_YxScIkb8b"
      },
      "source": [
        "# 6) Saving and re-loading models\n",
        "\n",
        "Now that we have a model that performs reasonably well, we want to save it. When you save models you save two things separatly 1) the architecture, which we is already saved, e.g. DFF.py, 2) the model weights, or state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0tBP6EYkb8c"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'MNIST_DFF1.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD4POvxlkb8c"
      },
      "source": [
        "When we want to retreave a trained model we also need to recover it in two stages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVP0vkKxkb8c"
      },
      "outputs": [],
      "source": [
        "#load model \n",
        "from Models import DFF as model # try DFF\n",
        "net2 = model().to(device)\n",
        "\n",
        "# load weights into model\n",
        "net2.load_state_dict(torch.load('MNIST_DFF1.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGrR9Oa7kb8d"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "DeepImageReconstruction",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "4dRnpXpXklNp",
        "1UE10cvCxH1m",
        "3vkXCTs6xNXI",
        "bAwmgnsz1-sx",
        "q6E9Tp75kb8O",
        "PsP9gsQDkb8T"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
